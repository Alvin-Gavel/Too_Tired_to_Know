\documentclass[10pt, twoside,a4paper]{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}
\usepackage[T1]{fontenc}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{units}
\usepackage{csquotes}
\usepackage{sidenotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{tikz}

\title{Documentation}
\author{Alvin Gavel}
\date{}

% Thanks to mikep in https://tex.stackexchange.com/a/279455

\newcommand{\shrug}[1][]{%
\begin{tikzpicture}[baseline,x=0.8\ht\strutbox,y=0.8\ht\strutbox,line width=0.125ex,#1]
\def\arm{(-2.5,0.95) to (-2,0.95) (-1.9,1) to (-1.5,0) (-1.35,0) to (-0.8,0)};
\draw \arm;
\draw[xscale=-1] \arm;
\def\headpart{(0.6,0) arc[start angle=-40, end angle=40,x radius=0.6,y radius=0.8]};
\draw \headpart;
\draw[xscale=-1] \headpart;
\def\eye{(-0.075,0.15) .. controls (0.02,0) .. (0.075,-0.15)};
\draw[shift={(-0.3,0.8)}] \eye;
\draw[shift={(0,0.85)}] \eye;
% draw mouth
\draw (-0.1,0.2) to [out=15,in=-100] (0.4,0.95); 
\end{tikzpicture}}

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{What are we trying to find out?}
We have given a group of participants five different tests. We have split them into a test group that has been subjected to sleep deprivation and a control group that has not\footnote{At least not systematically, as part of the experiment. Sometimes people just sleep badly.}. After each test we asked them to estimate their own performance. We now want to find out how sleep deprivation affects their estimated performance.

What complicates matters is that when the participants were asked to estimate how well they did, the participants were simply asked to rate their performance on a scale. This means that we have no straightforward way of checking how accurate their estimates are. If they had been asked to estimate what fraction of questions they got right, then we could straightforwardly say that, for example, someone who got $0.5$ right and estimates they got $0.8$ right did worse than someone who got $0.8$ right and estimates they got $0.9$ right. As it is, the first person might have estimated their performance as ``8'', and we simply do not know what -- in their mind -- that number was supposed to mean, which in turn means that we cannot say if it was close to their actual performance.

In Sect.~\ref{sec_binomial} we look at a simple way of working around this problem, and in Sect.~\ref{sec_cumulative} at a method that is arguably more sophisticated but also much harder to interpret.






\newpage
\section{What does the data look like?}
There are six csv-files in the directory \verb+Data+\footnote{It is currently not in the repo. This may change in the future.}:
\begin{itemize}
\item \verb+kss_data.csv+
\item \verb+arithmetic_data.csv+: Data from arithmetic test
\item \verb+working_memory_data.csv+: Data from working memory test
\item \verb+episodic_memory_data.csv+: Data from Episodic memory test
\item \verb+Stroop_data.csv+: Data from Stroop test
\item \verb+simple_attention_data.csv+: Data from simple reaction time test
\end{itemize}
At the moment, we only use the file \verb+kss_data.csv+. At time of writing I do not know what all columns are, so our best interpretation is this:
\begin{itemize}
\item \verb+id+: Participant ID
\item \verb+age+: Participant age
\item \verb+woman+: Participant gender
\item \verb+sd+: Participant sleep status
\item \verb+pair+: Participant pair for social interaction tasks
\item \verb+dyad_type+: Combination of sleep status in dyad
\item \verb+X1+: \shrug
\item \verb+date+: Date of test
\item \verb+clock+: Time of test
\item \verb+order_t+: Test order for each session
\item \verb+test_type+: Which cognitive test the participant just finished. This uses the abbreviations:
\begin{itemize}
\item \emph{M}: Arithmetic
\item \emph{W}: Working memory
\item \emph{ST}: Episodic memory
\item \emph{stroop}: Stroop
\item \emph{reactionTime}: Simple reaction time
\end{itemize}
\item \verb+rating1_type+: The type of rating in the column \verb+rating1+
\item \verb+rating1+: Self-rated sleepiness after each test. That is, the participant's response to the question ``How sleepy are you right now?''
\item \verb+rating2_type+: The type of rating in the column \verb+rating2+.
\item \verb+rating2+: Self-rated effort on each test. That is, the participant's response to the question ``How much of an effort did you make?''
\item \verb+rating3_type+: The type of rating in column \verb+rating1+
\item \verb+rating3+: Self-rated performance on each test. That is, the participant's response to the question ``How did you perform?''
\item \verb+time_adjustment_hours+: \shrug
\item \verb+old_time+: \shrug
\item \verb+correct+: This is a dummy column that can be ignored.
\item \verb+time+: Order of the session in the test battery
\end{itemize}
For now, the columns of interest to us are \verb+id+, \verb+sd+ and \verb+rating3+. We want to know how self-rated effort depends on sleep status.


\newpage
\section{Simple binomial test}\label{sec_binomial}
Instead of worrying about how to interpret what the participants' meant by the performance estimates they gave us, we simply look at how likely participants who gave a rating above the median are to also have performed above the median. That is, we have two binomial distribution with some probabilities $p^{\text{t}}_{\text{a, a}}$ and $p^{\text{c}}_{\text{a, a}}$, and we want to see if they differ enough for it to be clinically significant\footnote{A common mistake in this kind of study is to set up a ``null hypothesis'' that the two parameters are exactly the same, and then try to ``falsify'' that hypothesis by seeing if the difference is ``statistically significant''. Such a test is not scientifically meaningful. Since they are continuous parameters it is a priori given that they will differ my some amount, so that test would tell us nothing that we did not already know before we even gathered the data.}, where $t$ and $c$ denote the test and control group, respectively.

\subsection{Why $p^{\text{x}}_{\text{a, a}}$ alone tells us all we need to know}
We will only work with the probabilities $p^{\text{x}}_{\text{a, a}}$ that a participant in either group who had above-median performance also gave themselves an above-median rating, since this uniquely determines any other probabilities that we might be interested in. The corresponding probabilities $p^{\text{x}}_{\text{a, b}}$ that a person who performed above the median gave a rating below the median is trivially given by:
\begin{align}
p^{\text{x}}_{\text{a, b}} &= 1 - p^{\text{x}}_{\text{a, a}}.
\intertext{If we use $n$ to denote the corresponding numbers of participants, then the probability is also definitionally given as}
p^{\text{x}}_{\text{a, b}} &= \frac{n^{\text{x}}_{\text{a, b}}}{n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{a, b}}}. \label{eq_def_pxab}
\intertext{Analogiously, the probability $p^{\text{x}}_{\text{1, a}}$ that a participant who performed above median rated themselves above median is given by:}
p^{\text{x}}_{\text{a, a}} &= \frac{n^{\text{x}}_{\text{a, a}}}{n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{a, b}}}. \label{eq_def_pxaa}
\intertext{Analoguously, the probability $p^{\text{x}}_{\text{b, a}}$ that a participant who performed below median rated themselves above median is given by:}
p^{\text{x}}_{\text{b, a}} &= \frac{n^{\text{x}}_{\text{b, a}}}{n^{\text{x}}_{\text{b, a}} + n^{\text{x}}_{\text{b, b}}}. \label{eq_def_pxba}
\intertext{Analoguously, the probability $p^{\text{x}}_{\text{b, b}}$ that a participant who performed below median rated themselves below median is given by:}
p^{\text{x}}_{\text{b, b}} &= \frac{n^{\text{x}}_{\text{b, b}}}{n^{\text{x}}_{\text{b, a}} + n^{\text{x}}_{\text{b, b}}}. \label{eq_def_pxbb}
\intertext{Definitionally, the number of participants who performed above and below median are equal:}
n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{a, b}} &= n^{\text{x}}_{\text{b, a}} + n^{\text{x}}_{\text{b, b}} \label{eq_actual_perf}
\intertext{Analoguously, the numbers of participants who rated themselves above and below median are equal:}
n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{b, a}} &= n^{\text{x}}_{\text{a, b}} + n^{\text{x}}_{\text{b, b}} \label{eq_rated_perf}
\intertext{Adding both sides in \eqref{eq_actual_perf} and \eqref{eq_rated_perf} together and simplifying gives us:}
%2 n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{a, b}} + n^{\text{x}}_{\text{b, a}} &= n^{\text{x}}_{\text{a, b}} + n^{\text{x}}_{\text{b, a}} + 2n^{\text{x}}_{\text{b, b}} \notag \\
%2 n^{\text{x}}_{\text{a, a}} &= 2n^{\text{x}}_{\text{b, b}} \notag \\
n^{\text{x}}_{\text{a, a}} &= n^{\text{x}}_{\text{b, b}} \label{eq_naa_nbb}
\intertext{Analoguously, substracting both sides in \eqref{eq_actual_perf} and \eqref{eq_rated_perf} and simplifying gives us:}
%n^{\text{x}}_{\text{a, a}} + n^{\text{x}}_{\text{a, b}} - n^{\text{x}}_{\text{a, a}} - n^{\text{x}}_{\text{b, a}} &= n^{\text{x}}_{\text{b, a}} + n^{\text{x}}_{\text{b, b}} - n^{\text{x}}_{\text{a, b}} - n^{\text{x}}_{\text{b, b}} \\
%n^{\text{x}}_{\text{a, b}} - n^{\text{x}}_{\text{b, a}} &= n^{\text{x}}_{\text{b, a}} - n^{\text{x}}_{\text{a, b}}  \\
% 2 n^{\text{x}}_{\text{a, b}} &= 2 n^{\text{x}}_{\text{b, a}} \\
n^{\text{x}}_{\text{a, b}} &= n^{\text{x}}_{\text{b, a}} \label{eq_nab_nba}
\intertext{Inserting \eqref{eq_naa_nbb} and \eqref{eq_nab_nba} into \eqref{eq_def_pxba} we get:}
p^{\text{x}}_{\text{b, a}} &= \frac{n^{\text{x}}_{\text{a, b}}}{n^{\text{x}}_{\text{a, b}} + n^{\text{x}}_{\text{a, a}}} \notag
\intertext{Which, by \eqref{eq_def_pxab}, means that:}
&= p^{\text{x}}_{\text{a, b}}.
\intertext{Analogiously, inserting \eqref{eq_naa_nbb} and \eqref{eq_nab_nba} into \eqref{eq_def_pxba} gives us:}
p^{\text{x}}_{\text{b, b}} &= \frac{n^{\text{x}}_{\text{a, a}}}{n^{\text{x}}_{\text{a, b}} + n^{\text{x}}_{\text{a, a}}}
\intertext{Which, by \eqref{eq_def_pxaa}, means that:}
&= p^{\text{x}}_{\text{a, a}}.
\end{align}



\newpage
\section{Cumulative model}\label{sec_cumulative}
In the article \emph{Too Tired to Know} we implement the cumulative model described in Bürkner and Vuorre (2019). The reader is primarily recommended to that article for the details, or -- once it is written -- the section in our article that explains the analysis. This is mostly written for myself to force myself to understand how the model works, since the root of at least half of all evil is the use of statistical recipes without first understanding them.

\subsection{Basic idea}
The cumulative model starts out from the assumption that the ordinal variable that we actually measure, $Y$, is an increasing function of some underlying unobservable variable $\tilde{Y}$. Specifically it assumes that there are $K$ thresholds $\tau_k$ such that if $\tau_{k-1} < \tilde{Y} < \tau_{k}$ then we will observe $Y = k$. The underlying $\tilde{Y}$ in turn follows some probability density function $f$ such that the probability $P \left( Y = k \right)$ is given by
\begin{align}
P \left( Y = k \right) &= \int_{\tau_{k-1}}^{\tau_k} f \left( \tilde{Y} \right)  d \tilde{Y} \label{eq_Pyk_integral}
\intertext{If we call the corresponding cumulative density function $F$, this is}
&= F\left( \tau_k \right) - F\left( \tau_{k-1} \right)
\end{align}

\subsection{Linear model of prediction term}
So far the model is very general, but to get anywhere we need to make some assumptions about what the function $f$ actually looks like. We split $\tilde{Y}$ into a predictor term $\eta$ and an error term $\varepsilon$, so that
\begin{align}
\tilde{Y} &= \eta + \varepsilon \label{eq_terms}
\intertext{We now assume that $\eta$ is a linear function, so that}
\eta &= \sum_{n=0}^K b_n x_n \label{eq_linear}
\intertext{Inserting \eqref{eq_linear} into \eqref{eq_terms} gives us}
\tilde{Y} &= \sum_{n=0}^K b_n x_n + \varepsilon \label{eq_linear_2}
\end{align}
Since $d \tilde{Y} / d \varepsilon = 1$ we can rewrite \eqref{eq_Pyk_integral} as
\begin{align}
P \left( Y = k \right) &= \int_{\tau_{k-1}}^{\tau_k} f \left( \sum_{n=0}^K b_n x_n + \varepsilon \right)  d \varepsilon
\intertext{Shifting the integration boundaries by the predictor term gives us}
&= F \left( \tau_k - \sum_{n=0}^K b_n x_n \right) - F \left( \tau_{k-1} - \sum_{n=0}^K b_n x_n \right) \label{eq_linear_final}
\end{align}

\subsection{Normal model of error term}
We now need some kind of model of what that error term looks like. To make life simpler\footnote{It is common to justify assumptions of normality with reference to the central limit theorem. I would argue that this often over-interprets the central limit theorem as being much broader than it actually is, and that the real reason why normal distributions get used so often is that they are just so very convenient.}, we assume that it is normally distributed. If we denote the CDF of the normal distribution with $\Phi$, then \eqref{eq_linear_final} takes the form:
\begin{align}
P \left( Y = k \right) &=
\Phi \left( \tau_k - \sum_{n=0}^K b_n x_n \right) - \Phi \left( \tau_{k-1} - \sum_{n=0}^K b_n x_n \right)
\end{align}
This means we have a regression problem where we need to estimate the thresholds $\tau_k$ and $\tau_{k-1}$ and the regression coefficients $b_n$.





\end{document}